{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9gMPhdEs1SZ",
        "outputId": "c114f87b-ecb8-4857-f670-ebaa20259f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The required sample size per group: 175.38\n"
          ]
        }
      ],
      "source": [
        "#Exercise 1: Calculating Required Sample Size\n",
        "\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "# define the parameters\n",
        "effect_size = 0.3\n",
        "power = 0.8\n",
        "alpha = 0.05\n",
        "\n",
        "#calculate the required sample size\n",
        "analysis = TTestIndPower()\n",
        "sample_size = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "\n",
        "print(f'The required sample size per group: {sample_size:.2f}') #175.38 / group"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 2: Understanding the Relationship Between Effect Size and Sample Size\n",
        "\n",
        "\n",
        "# 0.2 effect size\n",
        "effect_size_one = 0.2\n",
        "effect_size_two = 0.4\n",
        "effect_size_three = 0.5\n",
        "\n",
        "sample_size_one = analysis.solve_power(effect_size=effect_size_one, alpha=alpha, power=power)\n",
        "sample_size_two = analysis.solve_power(effect_size=effect_size_two, alpha=alpha, power=power)\n",
        "sample_size_three = analysis.solve_power(effect_size=effect_size_three, alpha=alpha, power=power)\n",
        "\n",
        "print(f'The required sample size per group: \\nSample Size 0.2: {sample_size_one:.2f},\\nSample Size 0.4:{sample_size_two:.2f},\\nSample Size 0.5: {sample_size_three:.2f}')\n",
        "\n",
        "#Analysis: As effect size increases, the sample size decreases from 393.4 to 99.08 to 63. This is because larger effect sizes are easier to detect."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A_aW51qtBy5",
        "outputId": "6a7a55d0-7d6d-418e-8117-8e5f2279aa8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The required sample size per group: \n",
            "Sample Size 0.2: 393.41,\n",
            "Sample Size 0.4:99.08,\n",
            "Sample Size 0.5: 63.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ðŸŒŸ Exercise 3: Exploring the Impact of Statistical Power\n",
        "\n",
        "#effect_size = 0.2\n",
        "alpha = 0.05\n",
        "\n",
        "powers = [0.7, 0.8, 0.9]\n",
        "\n",
        "for p in powers:\n",
        "  n = analysis.solve_power(effect_size=effect_size, alpha=alpha,power=p)\n",
        "  print(f\"Power{p}: required sample size / group is {n:.2f}.\")\n",
        "\n",
        "  ##Analaysis: As power incr. sample size also increases which means we need more data to be sure. It means we need to keep thi sin mind when designing an A/B test to properly plan our controls for the test aganst our resourcing capabilities."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc6aHFl3tEAi",
        "outputId": "daf6b633-dba5-4564-b260-de08c88559f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Power0.7: required sample size / group is 138.12.\n",
            "Power0.8: required sample size / group is 175.38.\n",
            "Power0.9: required sample size / group is 234.46.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 4: Implementing Sequential Testing\n",
        "import numpy as np\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "alpha = 0.05\n",
        "#stoping criteria is when p-value is < 0.05 and max number of weeks is 4\n",
        "weekly_data = {\n",
        "    1: {\"A\": (30,1000), \"B\": (42, 1000)},\n",
        "    2: {\"A\": (55, 2000), \"B\": (75, 2000)},\n",
        "    3: {\"A\": (79, 3000), \"B\": (103, 3000)},\n",
        "}\n",
        "\n",
        "for week in weekly_data:\n",
        "    conv_A, total_A = weekly_data[week][\"A\"]\n",
        "    conv_B, total_B = weekly_data[week][\"B\"]\n",
        "\n",
        "    count = np.array([conv_A, conv_B])\n",
        "    nobs = np.array([total_A, total_B])\n",
        "\n",
        "    stat, p_value = proportions_ztest(count, nobs)\n",
        "\n",
        "    print(f\"Week {week}: p-value = {p_value:.4f}\")\n",
        "\n",
        "    # Check stopping rule\n",
        "    if p_value < alpha and (conv_B / total_B) > (conv_A / total_A):\n",
        "        print(f\"Stop at week {week}: Version B is significantly better.\\n\")\n",
        "        break\n",
        "else:\n",
        "    print(\"No early stop â€” continue test or evaluate at final week.\")\n",
        "\n",
        "\n",
        "    #Analaysis: if at 0.02, i'd continue, because it means that it still has more to go below my criteria."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAQE9Pa6tIJs",
        "outputId": "577b7c75-43fa-4a11-98cc-b54cae409daa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Week 1: p-value = 0.1498\n",
            "Week 2: p-value = 0.0745\n",
            "Week 3: p-value = 0.0708\n",
            "No early stop â€” continue test or evaluate at final week.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 5: Applying Bayesian A/B Testing\n",
        "\n",
        "##Youâ€™re testing a new feature in your app, and you want to use a Bayesian approach. Initially, you believe the new feature has a 50% chance of improving user engagement. After collecting data, your analysis suggests a 65% probability that the new feature is better.\n",
        "\n",
        "    ###Describe how you would set up your prior belief: I believe the 50% chance is net neutral so i don't need to set up anything new.\n",
        "    ##After collecting data, how does the updated belief (posterior distribution) influence your decision?: THere is some evidence its better but honestly not strong enough to show that the new feature is SO much better. We need to continue the test.\n",
        "    ###What would you do if the posterior probability was only 55%?: This is not strong enough to say that th enew feature is better and i would not use this as evidence at all. i may look at nother varabiel instead.\n"
      ],
      "metadata": {
        "id": "ptsMwQqQtL6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 6: Implementing Adaptive Experimentation\n",
        "\n",
        "##Youâ€™re running a test with three different website layouts to increase user engagement. Initially, each layout gets 33% of the traffic. After the first week, Layout C shows higher engagement.\n",
        "\n",
        "###Explain how you would adjust the traffic allocation after the first week: I wouldn't do anything just yet until I see much higher engagement (like 75%+ ). If its consistent, then I would begin shifting by 10% more each week.\n",
        "\n",
        "###Describe how you would continue to adapt the experiment in the following weeks: Divert from 33 - 43% of teh traffic in week 3 (if the first two weeks are execessively high). Reduce the traffic by 5% to a an db.\n",
        "\n",
        "###What challenges might you face with adaptive experimentation, and how would you address them? : It could be confirmation bias, so we need to shift slowly.\n"
      ],
      "metadata": {
        "id": "Hfv7Wm4StMaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B_ZO3mThyzAv"
      }
    }
  ]
}